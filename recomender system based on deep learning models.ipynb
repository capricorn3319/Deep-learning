{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "J2oae4g7Q1wG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "from zipfile import ZipFile\n",
        "from urllib.request import urlretrieve\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import StringLookup\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive') \n",
        "import pathlib \n",
        "path = pathlib.Path(\"/content/drive/MyDrive/eyd\") \n",
        "%cd /content/drive/MyDrive/eyd\n",
        "%ls"
      ],
      "metadata": {
        "id": "YZZJ7fxIQ2kT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7be3c7d2-5416-48a9-bd71-686501ba1540"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/eyd\n",
            "test_data.csv  train.csv  train_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data\n",
        "data = pd.read_csv('train.csv')[:92107]"
      ],
      "metadata": {
        "id": "-3Sn-RbMU7sF"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "FsDq-tWrVgGN",
        "outputId": "cf0e2ef6-7901-4e02-dfbc-fc5aaa48291c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       userId  itemId  rating                 date\n",
              "0      cgexjc  682978       4  2017-08-13 13:23:35\n",
              "1      cgexjc  320898       4  2019-01-18 15:56:07\n",
              "2      cgexjc   29028       4  2017-08-13 14:03:55\n",
              "3      cgexjc  399148       5  2017-08-13 13:59:51\n",
              "4      cgexjc  734055       4  2019-01-18 15:37:29\n",
              "...       ...     ...     ...                  ...\n",
              "92102  ajaznj  315704       4  2017-02-11 03:13:22\n",
              "92103  ajaznj   52542       3  2017-02-12 19:39:31\n",
              "92104  ajaznj  522434       3  2017-03-29 20:16:49\n",
              "92105  ucihsk  399148       5  2020-04-24 19:45:57\n",
              "92106  ucihsk  734055       5  2020-08-18 21:33:56\n",
              "\n",
              "[92107 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5accca3e-561a-49ad-a272-6ca1802527d9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>itemId</th>\n",
              "      <th>rating</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cgexjc</td>\n",
              "      <td>682978</td>\n",
              "      <td>4</td>\n",
              "      <td>2017-08-13 13:23:35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cgexjc</td>\n",
              "      <td>320898</td>\n",
              "      <td>4</td>\n",
              "      <td>2019-01-18 15:56:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cgexjc</td>\n",
              "      <td>29028</td>\n",
              "      <td>4</td>\n",
              "      <td>2017-08-13 14:03:55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cgexjc</td>\n",
              "      <td>399148</td>\n",
              "      <td>5</td>\n",
              "      <td>2017-08-13 13:59:51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cgexjc</td>\n",
              "      <td>734055</td>\n",
              "      <td>4</td>\n",
              "      <td>2019-01-18 15:37:29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92102</th>\n",
              "      <td>ajaznj</td>\n",
              "      <td>315704</td>\n",
              "      <td>4</td>\n",
              "      <td>2017-02-11 03:13:22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92103</th>\n",
              "      <td>ajaznj</td>\n",
              "      <td>52542</td>\n",
              "      <td>3</td>\n",
              "      <td>2017-02-12 19:39:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92104</th>\n",
              "      <td>ajaznj</td>\n",
              "      <td>522434</td>\n",
              "      <td>3</td>\n",
              "      <td>2017-03-29 20:16:49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92105</th>\n",
              "      <td>ucihsk</td>\n",
              "      <td>399148</td>\n",
              "      <td>5</td>\n",
              "      <td>2020-04-24 19:45:57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92106</th>\n",
              "      <td>ucihsk</td>\n",
              "      <td>734055</td>\n",
              "      <td>5</td>\n",
              "      <td>2020-08-18 21:33:56</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>92107 rows Ã— 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5accca3e-561a-49ad-a272-6ca1802527d9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5accca3e-561a-49ad-a272-6ca1802527d9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5accca3e-561a-49ad-a272-6ca1802527d9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"userId\"] = data[\"userId\"].apply(lambda x: f\"user_{x}\")\n",
        "data[\"itemId\"] = data[\"itemId\"].apply(lambda x: f\"item_{x}\")\n",
        "data[\"rating\"] = data[\"rating\"].apply(lambda x: float(x))"
      ],
      "metadata": {
        "id": "6NzqJzu4z4VS"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_group = data.sort_values(by=[\"date\"]).groupby(\"userId\")\n",
        "\n",
        "ratings_data = pd.DataFrame(\n",
        "    data={\n",
        "        \"userId\": list(ratings_group.groups.keys()),\n",
        "        \"itemId\": list(ratings_group.itemId.apply(list)),\n",
        "        \"ratings\": list(ratings_group.rating.apply(list)),\n",
        "        \"date\": list(ratings_group.date.apply(list)),\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "qx6szhVHz-hN"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 6\n",
        "step_size = 2"
      ],
      "metadata": {
        "id": "ERzazcEYTatC"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences(values, window_size, step_size):\n",
        "    sequences = []\n",
        "    start_index = 0\n",
        "    while True:\n",
        "        end_index = start_index + window_size\n",
        "        seq = values[start_index:end_index]\n",
        "        if len(seq) < window_size:\n",
        "            seq = values[-window_size:]\n",
        "            if len(seq) == window_size:\n",
        "                sequences.append(seq)\n",
        "            break\n",
        "        sequences.append(seq)\n",
        "        start_index += step_size\n",
        "    return sequences\n",
        "\n",
        "\n",
        "ratings_data.itemId = ratings_data.itemId.apply(\n",
        "    lambda ids: create_sequences(ids, sequence_length, step_size)\n",
        ")\n",
        "\n",
        "ratings_data.ratings = ratings_data.ratings.apply(\n",
        "    lambda ids: create_sequences(ids, sequence_length, step_size)\n",
        ")\n",
        "\n",
        "del ratings_data[\"date\"]"
      ],
      "metadata": {
        "id": "3cbiDy5T0iyh"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_data_item = ratings_data[[\"userId\", \"itemId\"]].explode(\n",
        "    \"itemId\", ignore_index=True\n",
        ")\n",
        "ratings_data_rating = ratings_data[[\"ratings\"]].explode(\"ratings\", ignore_index=True)\n",
        "ratings_data_transformed = pd.concat([ratings_data_item, ratings_data_rating], axis=1)\n",
        "\n",
        "ratings_data_transformed.itemId = ratings_data_transformed.itemId.str.join(',')\n",
        "\n",
        "ratings_data_transformed = ratings_data_transformed.dropna(subset=['ratings'])\n",
        "\n",
        "ratings_data_transformed.ratings = ratings_data_transformed.ratings.apply(\n",
        "    lambda x: \",\".join([str(v) for v in x])\n",
        ")\n",
        "\n",
        "ratings_data_transformed.rename(\n",
        "    columns={\"itemId\": \"sequence_item_ids\", \"ratings\": \"sequence_ratings\"},\n",
        "    inplace=True,\n",
        ")"
      ],
      "metadata": {
        "id": "uRNSkjKK1NLS"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_selection = np.random.rand(len(ratings_data_transformed.index)) <= 0.85\n",
        "train_data = ratings_data_transformed[random_selection]\n",
        "test_data = ratings_data_transformed[~random_selection]\n",
        "\n",
        "train_data.to_csv(\"train_data.csv\", index=False, sep=\"|\", header=False)\n",
        "test_data.to_csv(\"test_data.csv\", index=False, sep=\"|\", header=False)"
      ],
      "metadata": {
        "id": "rZto2Y2MMRGl"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CSV_HEADER = list(ratings_data_transformed.columns)\n",
        "\n",
        "CATEGORICAL_FEATURES_WITH_VOCABULARY = {\n",
        "    \"userId\": list(data.userId.unique()),\n",
        "    \"itemId\": list(data.itemId.unique()),\n",
        "}"
      ],
      "metadata": {
        "id": "AikOmnVA2OtJ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset_from_csv(csv_file_path, shuffle=False, batch_size=128):\n",
        "    def process(features):\n",
        "        items_ids_string = features[\"sequence_item_ids\"]\n",
        "        sequence_items_ids = tf.strings.split(items_ids_string, \",\").to_tensor()\n",
        "\n",
        "        # The last item id in the sequence is the target item.\n",
        "        features[\"target_item_id\"] = sequence_items_ids[:, -1]\n",
        "        features[\"sequence_item_ids\"] = sequence_items_ids[:, :-1]\n",
        "        \n",
        "        ratings_string = features[\"sequence_ratings\"]\n",
        "        sequence_ratings = tf.strings.to_number(\n",
        "            tf.strings.split(ratings_string, \",\"), tf.dtypes.float32\n",
        "        ).to_tensor()\n",
        "\n",
        "        # The last rating in the sequence is the target for the model to predict.\n",
        "        target = sequence_ratings[:, -1]\n",
        "        features[\"sequence_ratings\"] = sequence_ratings[:, :-1]\n",
        "\n",
        "        return features, target\n",
        "\n",
        "    dataset = tf.data.experimental.make_csv_dataset(\n",
        "        csv_file_path,\n",
        "        batch_size=batch_size,\n",
        "        column_names=CSV_HEADER,\n",
        "        num_epochs=1,\n",
        "        header=False,\n",
        "        field_delim=\"|\",\n",
        "        shuffle=shuffle,\n",
        "    ).map(process)\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "kXRHT3CE2VWi"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model_inputs():\n",
        "    return {\n",
        "        \"userId\": layers.Input(name=\"userId\", shape=(1,), dtype=tf.string),\n",
        "        \"sequence_item_ids\": layers.Input(\n",
        "            name=\"sequence_item_ids\", shape=(sequence_length - 1,), dtype=tf.string\n",
        "        ),\n",
        "        \"target_item_id\": layers.Input(\n",
        "            name=\"target_item_id\", shape=(1,), dtype=tf.string\n",
        "        ),\n",
        "        \"sequence_ratings\": layers.Input(\n",
        "            name=\"sequence_ratings\", shape=(sequence_length - 1,), dtype=tf.float32\n",
        "        )}"
      ],
      "metadata": {
        "id": "1Urb-hKe2d41"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_input_features(\n",
        "    inputs,\n",
        "    include_user_id=True,\n",
        "    include_user_features=False,\n",
        "    include_item_features=False,\n",
        "):\n",
        "\n",
        "    encoded_transformer_features = []\n",
        "    encoded_other_features = []\n",
        "\n",
        "    other_feature_names = []\n",
        "    if include_user_id:\n",
        "        other_feature_names.append(\"user_id\")\n",
        "    if include_user_features:\n",
        "        other_feature_names.extend(USER_FEATURES)\n",
        "\n",
        "    ## Encode user features\n",
        "    for feature_name in other_feature_names:\n",
        "        # Convert the string input values into integer indices.\n",
        "        vocabulary = CATEGORICAL_FEATURES_WITH_VOCABULARY[feature_name]\n",
        "        idx = StringLookup(vocabulary=vocabulary, mask_token=None, num_oov_indices=0)(\n",
        "            inputs[feature_name]\n",
        "        )\n",
        "        # Compute embedding dimensions\n",
        "        embedding_dims = int(math.sqrt(len(vocabulary)))\n",
        "        # Create an embedding layer with the specified dimensions.\n",
        "        embedding_encoder = layers.Embedding(\n",
        "            input_dim=len(vocabulary),\n",
        "            output_dim=embedding_dims,\n",
        "            name=f\"{feature_name}_embedding\",\n",
        "        )\n",
        "        # Convert the index values to embedding representations.\n",
        "        encoded_other_features.append(embedding_encoder(idx))\n",
        "\n",
        "    ## Create a single embedding vector for the user features\n",
        "    if len(encoded_other_features) > 1:\n",
        "        encoded_other_features = layers.concatenate(encoded_other_features)\n",
        "    elif len(encoded_other_features) == 1:\n",
        "        encoded_other_features = encoded_other_features[0]\n",
        "    else:\n",
        "        encoded_other_features = None\n",
        "\n",
        "    ## Create a item embedding encoder\n",
        "    item_vocabulary = CATEGORICAL_FEATURES_WITH_VOCABULARY[\"itemId\"]\n",
        "    item_embedding_dims = int(math.sqrt(len(item_vocabulary)))\n",
        "    # Create a lookup to convert string values to integer indices.\n",
        "    item_index_lookup = StringLookup(\n",
        "        vocabulary=item_vocabulary,\n",
        "        mask_token=None,\n",
        "        num_oov_indices=0,\n",
        "        name=\"item_index_lookup\",\n",
        "    )\n",
        "    # Create an embedding layer with the specified dimensions.\n",
        "    item_embedding_encoder = layers.Embedding(\n",
        "        input_dim=len(item_vocabulary),\n",
        "        output_dim=item_embedding_dims,\n",
        "        name=f\"item_embedding\",\n",
        "    )\n",
        "    # Create a processing layer for genres.\n",
        "    item_embedding_processor = layers.Dense(\n",
        "        units=item_embedding_dims,\n",
        "        activation=\"relu\",\n",
        "        name=\"process_item_embedding_with_genres\",\n",
        "    )\n",
        "\n",
        "    ## Define a function to encode a given item id.\n",
        "    def encode_item(item_id):\n",
        "        # Convert the string input values into integer indices.\n",
        "        item_idx = item_index_lookup(item_id)\n",
        "        item_embedding = item_embedding_encoder(item_idx)\n",
        "        encoded_item = item_embedding\n",
        "        if include_item_features:\n",
        "            item_genres_vector = item_genres_lookup(item_idx)\n",
        "            encoded_item = item_embedding_processor(\n",
        "                layers.concatenate([item_embedding, item_genres_vector])\n",
        "            )\n",
        "        return encoded_item\n",
        "\n",
        "    ## Encoding target_item_id\n",
        "    target_item_id = inputs[\"target_item_id\"]\n",
        "    encoded_target_item = encode_item(target_item_id)\n",
        "\n",
        "    ## Encoding sequence item_ids.\n",
        "    sequence_items_ids = inputs[\"sequence_item_ids\"]\n",
        "    encoded_sequence_items = encode_item(sequence_items_ids)\n",
        "    # Create positional embedding.\n",
        "    position_embedding_encoder = layers.Embedding(\n",
        "        input_dim=sequence_length,\n",
        "        output_dim=item_embedding_dims,\n",
        "        name=\"position_embedding\",\n",
        "    )\n",
        "    positions = tf.range(start=0, limit=sequence_length - 1, delta=1)\n",
        "    encodded_positions = position_embedding_encoder(positions)\n",
        "    # Retrieve sequence ratings to incorporate them into the encoding of the item.\n",
        "    sequence_ratings = tf.expand_dims(inputs[\"sequence_ratings\"], -1)\n",
        "    # Add the positional encoding to the item encodings and multiply them by rating.\n",
        "    encoded_sequence_items_with_poistion_and_rating = layers.Multiply()(\n",
        "        [(encoded_sequence_items + encodded_positions), sequence_ratings]\n",
        "    )\n",
        "\n",
        "    # Construct the transformer inputs.\n",
        "    for encoded_item in tf.unstack(\n",
        "        encoded_sequence_items_with_poistion_and_rating, axis=1\n",
        "    ):\n",
        "        encoded_transformer_features.append(tf.expand_dims(encoded_item, 1))\n",
        "    encoded_transformer_features.append(encoded_target_item)\n",
        "\n",
        "    encoded_transformer_features = layers.concatenate(\n",
        "        encoded_transformer_features, axis=1\n",
        "    )\n",
        "\n",
        "    return encoded_transformer_features, encoded_other_features\n"
      ],
      "metadata": {
        "id": "M9nOo-NrA74j"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a BST model\n",
        "\n",
        "include_user_id = False\n",
        "include_user_features = False\n",
        "include_item_features = False\n",
        "\n",
        "hidden_units = [256, 128]\n",
        "dropout_rate = 0.1\n",
        "num_heads = 3"
      ],
      "metadata": {
        "id": "jqxXy-yxTo2d"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    inputs = create_model_inputs()\n",
        "    transformer_features, other_features = encode_input_features(\n",
        "        inputs, include_user_id, include_user_features, include_item_features\n",
        "    )\n",
        "\n",
        "    # Create a multi-headed attention layer.\n",
        "    attention_output = layers.MultiHeadAttention(\n",
        "        num_heads=num_heads, key_dim=transformer_features.shape[2], dropout=dropout_rate\n",
        "    )(transformer_features, transformer_features)\n",
        "\n",
        "    # Transformer block.\n",
        "    attention_output = layers.Dropout(dropout_rate)(attention_output)\n",
        "    x1 = layers.Add()([transformer_features, attention_output])\n",
        "    x1 = layers.LayerNormalization()(x1)\n",
        "    x2 = layers.LeakyReLU()(x1)\n",
        "    x2 = layers.Dense(units=x2.shape[-1])(x2)\n",
        "    x2 = layers.Dropout(dropout_rate)(x2)\n",
        "    transformer_features = layers.Add()([x1, x2])\n",
        "    transformer_features = layers.LayerNormalization()(transformer_features)\n",
        "    features = layers.Flatten()(transformer_features)\n",
        "\n",
        "    # Included the other features.\n",
        "    if other_features is not None:\n",
        "        features = layers.concatenate(\n",
        "            [features, layers.Reshape([other_features.shape[-1]])(other_features)]\n",
        "        )\n",
        "\n",
        "    # Fully-connected layers.\n",
        "    for num_units in hidden_units:\n",
        "        features = layers.Dense(num_units)(features)\n",
        "        features = layers.BatchNormalization()(features)\n",
        "        features = layers.LeakyReLU()(features)\n",
        "        features = layers.Dropout(dropout_rate)(features)\n",
        "\n",
        "    outputs = layers.Dense(units=1)(features)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "model = create_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "539VAaL3Fzgk",
        "outputId": "464061a7-ec23-458c-ff1f-ca9b3428c13d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/numpy/core/numeric.py:2468: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  return bool(asarray(a1 == a2).all())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adagrad(learning_rate=0.01),\n",
        "    loss=keras.losses.MeanSquaredError(),\n",
        "    metrics=[keras.metrics.MeanAbsoluteError()],\n",
        ")\n",
        "\n",
        "# Read the training data.\n",
        "train_dataset = get_dataset_from_csv(\"train_data.csv\", shuffle=True, batch_size=265)\n",
        "\n",
        "# Fit the model with the training data.\n",
        "model.fit(train_dataset, epochs=5)\n",
        "\n",
        "# Read the test data.\n",
        "test_dataset = get_dataset_from_csv(\"test_data.csv\", batch_size=265)\n",
        "\n",
        "# Evaluate the model on the test data.\n",
        "_, rmse = model.evaluate(test_dataset, verbose=0)\n",
        "print(f\"Test MAE: {round(rmse, 3)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tW15Ur0LF7d_",
        "outputId": "227447fa-1f4a-4d0b-e31d-71a33f3d1ed0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "146/146 [==============================] - 25s 157ms/step - loss: 1.7487 - mean_absolute_error: 1.0194\n",
            "Epoch 2/5\n",
            "146/146 [==============================] - 25s 174ms/step - loss: 1.0318 - mean_absolute_error: 0.8058\n",
            "Epoch 3/5\n",
            "146/146 [==============================] - 17s 116ms/step - loss: 0.9237 - mean_absolute_error: 0.7600\n",
            "Epoch 4/5\n",
            "146/146 [==============================] - 17s 117ms/step - loss: 0.8434 - mean_absolute_error: 0.7251\n",
            "Epoch 5/5\n",
            "146/146 [==============================] - 17s 118ms/step - loss: 0.7771 - mean_absolute_error: 0.6966\n",
            "Test MAE: 0.775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "COD-PUmBLxzX"
      },
      "execution_count": 50,
      "outputs": []
    }
  ]
}