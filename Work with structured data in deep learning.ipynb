{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GhG5MCmuXPT"
      },
      "outputs": [],
      "source": [
        "pip install tensorflow==2.12"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "GNgKQIBRvTMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive') \n",
        "import pathlib \n",
        "InputPath = pathlib.Path(\"/content/drive/MyDrive/eyd\") \n",
        "%cd /content/drive/MyDrive/eyd \n",
        "%ls"
      ],
      "metadata": {
        "id": "RRpt36bvw-kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "he=['Elevation', 'Aspect', 'Slope','Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n",
        "    'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon',\n",
        "       'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points',\n",
        "       'Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3',\n",
        "       'Wilderness_Area4', 'Soil_Type1', 'Soil_Type2', 'Soil_Type3',\n",
        "       'Soil_Type4', 'Soil_Type5', 'Soil_Type6', 'Soil_Type7', 'Soil_Type8',\n",
        "       'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12',\n",
        "       'Soil_Type13', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16',\n",
        "       'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20',\n",
        "       'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24',\n",
        "       'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28',\n",
        "       'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32',\n",
        "       'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36',\n",
        "       'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40',\n",
        "       'target']\n",
        "dataframe = pd.read_csv('q1-covtype.data.gz', names=he)"
      ],
      "metadata": {
        "id": "jFOZFjjHxDmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.head()"
      ],
      "metadata": {
        "id": "zbeQ_Qi4KHdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataframe.shape)"
      ],
      "metadata": {
        "id": "Eh5nv6YyxSHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uVDj0zJEIj7"
      },
      "outputs": [],
      "source": [
        "dataframe.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quUwJSXPEIj8"
      },
      "outputs": [],
      "source": [
        "val_dataframe = dataframe.sample(frac=0.2, random_state=1337)\n",
        "train_dataframe = dataframe.drop(val_dataframe.index)\n",
        "\n",
        "print(\n",
        "    \"Using %d samples for training and %d for validation\"\n",
        "    % (len(train_dataframe), len(val_dataframe))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dataframe_to_dataset(dataframe):\n",
        "    dataframe = dataframe.copy()\n",
        "    labels = dataframe.pop(\"target\")\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "    return ds\n",
        "\n",
        "\n",
        "train_ds = dataframe_to_dataset(train_dataframe)\n",
        "val_ds = dataframe_to_dataset(val_dataframe)"
      ],
      "metadata": {
        "id": "B9MN6JVVxcXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in train_ds.take(1):\n",
        "    print(\"Input:\", x)\n",
        "    print(\"Target:\", y)"
      ],
      "metadata": {
        "id": "aeMZiP9axhX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.batch(32)\n",
        "val_ds = val_ds.batch(32)"
      ],
      "metadata": {
        "id": "qiKYzfKKxl7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import FeatureSpace"
      ],
      "metadata": {
        "id": "f4By8F8g6HR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_space = FeatureSpace(\n",
        "    features={\n",
        "        # Categorical features encoded as integers\n",
        "        \"Slope\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
        "        \"Wilderness_Area1\":\"integer_categorical\",\n",
        "        \"Wilderness_Area2\":\"integer_categorical\",\n",
        "        \"Wilderness_Area3\":\"integer_categorical\",\n",
        "        \"Wilderness_Area4\":\"integer_categorical\",\n",
        "        \"Soil_Type1\": \"integer_categorical\",\n",
        "        \"Soil_Type2\": \"integer_categorical\",\n",
        "        \"Soil_Type3\": \"integer_categorical\",\n",
        "        \"Soil_Type4\": \"integer_categorical\",\n",
        "        \"Soil_Type5\": \"integer_categorical\",\n",
        "        \"Soil_Type6\": \"integer_categorical\",\n",
        "        \"Soil_Type7\": \"integer_categorical\",\n",
        "        \"Soil_Type8\": \"integer_categorical\",\n",
        "        \"Soil_Type9\": \"integer_categorical\",\n",
        "        \"Soil_Type10\": \"integer_categorical\",\n",
        "        \"Soil_Type11\": \"integer_categorical\",\n",
        "        \"Soil_Type12\": \"integer_categorical\",\n",
        "        \"Soil_Type13\": \"integer_categorical\",\n",
        "        \"Soil_Type14\": \"integer_categorical\",\n",
        "        \"Soil_Type15\": \"integer_categorical\",\n",
        "        \"Soil_Type16\": \"integer_categorical\",\n",
        "        \"Soil_Type17\": \"integer_categorical\",\n",
        "        \"Soil_Type18\": \"integer_categorical\",\n",
        "        \"Soil_Type19\": \"integer_categorical\",\n",
        "        \"Soil_Type20\": \"integer_categorical\",\n",
        "        \"Soil_Type21\": \"integer_categorical\",\n",
        "        \"Soil_Type22\": \"integer_categorical\",\n",
        "        \"Soil_Type23\": \"integer_categorical\",\n",
        "        \"Soil_Type24\": \"integer_categorical\",\n",
        "        \"Soil_Type25\": \"integer_categorical\",\n",
        "        \"Soil_Type26\": \"integer_categorical\",\n",
        "        \"Soil_Type27\": \"integer_categorical\",\n",
        "        \"Soil_Type28\": \"integer_categorical\",\n",
        "        \"Soil_Type29\": \"integer_categorical\",\n",
        "        \"Soil_Type30\": \"integer_categorical\",\n",
        "        \"Soil_Type31\": \"integer_categorical\",\n",
        "        \"Soil_Type32\": \"integer_categorical\",\n",
        "        \"Soil_Type33\": \"integer_categorical\",\n",
        "        \"Soil_Type34\": \"integer_categorical\",\n",
        "        \"Soil_Type35\": \"integer_categorical\",\n",
        "        \"Soil_Type36\": \"integer_categorical\",\n",
        "        \"Soil_Type37\": \"integer_categorical\",\n",
        "        \"Soil_Type38\": \"integer_categorical\",\n",
        "        \"Soil_Type39\": \"integer_categorical\",\n",
        "        \"Soil_Type40\": \"integer_categorical\",\n",
        "\n",
        "        # Numerical features to normalize\n",
        "        \"Aspect\": \"float_normalized\",\n",
        "        \"Horizontal_Distance_To_Hydrology\": \"float_normalized\",\n",
        "        \"Vertical_Distance_To_Hydrology\": \"float_normalized\",\n",
        "        \"Horizontal_Distance_To_Roadways\": \"float_normalized\",\n",
        "        \"Hillshade_9am\": \"float_normalized\",\n",
        "        \"Hillshade_Noon\": \"float_normalized\",\n",
        "        \"Hillshade_3pm\": \"float_normalized\",\n",
        "        \"Horizontal_Distance_To_Fire_Points\": \"float_normalized\",\n",
        "        \"Elevation\": \"float_normalized\",\n",
        "    },\n",
        "\n",
        "    output_mode=\"concat\",\n",
        ")"
      ],
      "metadata": {
        "id": "Dd90MCE6xx9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds_with_no_labels = train_ds.map(lambda x, _: x)\n",
        "feature_space.adapt(train_ds_with_no_labels)"
      ],
      "metadata": {
        "id": "eIGlwv2GyrLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x, _ in train_ds.take(1):\n",
        "    preprocessed_x = feature_space(x)\n",
        "    print(\"preprocessed_x.shape:\", preprocessed_x.shape)\n",
        "    print(\"preprocessed_x.dtype:\", preprocessed_x.dtype)"
      ],
      "metadata": {
        "id": "QV9JYnmEyuPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_train_ds = train_ds.map(\n",
        "    lambda x, y: (feature_space(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
        ")\n",
        "preprocessed_train_ds = preprocessed_train_ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "preprocessed_val_ds = val_ds.map(\n",
        "    lambda x, y: (feature_space(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
        ")\n",
        "preprocessed_val_ds = preprocessed_val_ds.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "k4zPHTjb0_SB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_inputs = feature_space.get_inputs()\n",
        "encoded_features = feature_space.get_encoded_features()\n",
        "\n",
        "x = keras.layers.Dense(32, activation=\"relu\")(encoded_features)\n",
        "x = keras.layers.Dropout(0.5)(x)\n",
        "predictions = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "training_model = keras.Model(inputs=encoded_features, outputs=predictions)\n",
        "training_model.compile(\n",
        "    optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "inference_model = keras.Model(inputs=dict_inputs, outputs=predictions)"
      ],
      "metadata": {
        "id": "TdeaeifQBcn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_model.fit(\n",
        "    preprocessed_train_ds, epochs=20, validation_data=preprocessed_val_ds, verbose=2\n",
        ")"
      ],
      "metadata": {
        "id": "oq7kkvMkBcrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = dataframe[0:1].pop(\"target\")\n",
        "\n",
        "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
        "predictions = inference_model.predict(input_dict)\n",
        "\n",
        "print(\n",
        "    f\"This particular patient had a {100 * predictions[0][0]:.2f}% probability \"\n",
        "    \"of having a heart disease, as evaluated by our model.\"\n",
        ")"
      ],
      "metadata": {
        "id": "LvDTXfa5BcuD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}